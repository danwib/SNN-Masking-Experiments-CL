name: stage4_sequential_mixed_soft_sleep
experiment_type: sequential
tasks:
  - name: mnist_task1
    prompt: mnist_task1
    column_index: 0
    dataset_variant: task1
  - name: mnist_task2
    prompt: mnist_task2
    column_index: 1
    dataset_variant: task2
  - name: fashion_task1
    prompt: fashion_task1
    column_index: 2
    dataset_variant: fashion_task1
    dataset_name: fashion_mnist
  - name: fashion_task2
    prompt: fashion_task2
    column_index: 3
    dataset_variant: fashion_task2
    dataset_name: fashion_mnist
  - name: mnist_task1_prime
    prompt: mnist_task1_prime
    column_index: 4
    dataset_variant: task1
    held_out: true
    consolidate_into: mnist_task1
  - name: mnist_task2_prime
    prompt: mnist_task2_prime
    column_index: 5
    dataset_variant: task2
    held_out: true
    consolidate_into: mnist_task2
  - name: fashion_task1_prime
    prompt: fashion_task1_prime
    column_index: 6
    dataset_variant: fashion_task1
    dataset_name: fashion_mnist
    held_out: true
    consolidate_into: fashion_task1
  - name: fashion_task2_prime
    prompt: fashion_task2_prime
    column_index: 7
    dataset_variant: fashion_task2
    dataset_name: fashion_mnist
    held_out: true
    consolidate_into: fashion_task2
dataset:
  root: assets/data
  default_dataset: mnist
  held_out_fraction: 0.2
  max_train_samples: 4000
  use_fake_data: false
  download: true
training:
  epochs: 25
  batch_size: 64
  base_learning_rate: 0.02
  seed: 59
  task_schedule:
    - mnist_task1
    - mnist_task2
    - fashion_task1
    - fashion_task2
    - mnist_task1
    - mnist_task2
    - fashion_task1
    - fashion_task2
masking:
  learning_rate_scale: 0.35
  threshold_shift: 0.2
  prompt_vector_dim: 16
  mode: soft_columns
  soft_columns:
    total_columns: 12
    base_columns: 8
    base_tasks:
      - mnist_task1
      - mnist_task2
      - fashion_task1
      - fashion_task2
    novel_tasks:
      - mnist_task1_prime
      - mnist_task2_prime
      - fashion_task1_prime
      - fashion_task2_prime
    temperature: 0.28
    lambda_entropy: 0.02
    lambda_balance: 0.03
    lambda_overlap_novel: 0.02
    mask_learning_rate: 0.05
model:
  hidden_per_column: 32
  time_steps: 5
  beta: 0.9
sleep:
  enabled: true
  epochs: 15
  batch_size: 64
  label_weight: 0.0
  distillation_weight: 1.0
  temperature: 1.5
  held_out_replay: 2
